{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad78dc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fbref.com/en/comps/9/2018-2019/2018-2019-Premier-League-Stats\n",
      "https://fbref.com/en/comps/9/2019-2020/2019-2020-Premier-League-Stats\n",
      "https://fbref.com/en/comps/9/2020-2021/2020-2021-Premier-League-Stats\n",
      "https://fbref.com/en/comps/9/2021-2022/2021-2022-Premier-League-Stats\n",
      "https://fbref.com/en/comps/9/2022-2023/2022-2023-Premier-League-Stats\n",
      "https://fbref.com/en/comps/9/2023-2024/2023-2024-Premier-League-Stats\n"
     ]
    }
   ],
   "source": [
    "# Define the list of seasons\n",
    "seasons = [\"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "base_url = \"https://fbref.com/en/comps/9/{season}/{season}-Premier-League-Stats\"\n",
    "\n",
    "# Print the URLs for verification\n",
    "for season in seasons:\n",
    "    url = base_url.format(season=season)\n",
    "    print(url)  # Print each URL to confirm it matches the expected format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64db9fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "      \n",
      "<!DOCTYPE html>\n",
      "<html data-version=\"klecko-\" data-root=\"/home/fb/deploy/www/base\" lang=\"en\" class=\"no-js\" >\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=2.0\" />\n",
      "    <link rel=\"dns-prefetch\" href=\"https://cdn.ssref.net/req/202504030\" />\n",
      "<script>\n",
      "/* https://docs.osano.com/hc/en-us/articles/22469433444372-Google-Consent-Mode-v2  */\n",
      "  window.dataLayer = w\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL for the test season (2023-2024)\n",
    "url = \"https://fbref.com/en/comps/9/2023-2024/2023-2024-Premier-League-Stats\"\n",
    "\n",
    "# Fetch the HTML content\n",
    "response = requests.get(url)\n",
    "\n",
    "# Print the first 500 characters of the HTML to verify\n",
    "print(response.text[:500])  # Print the first 500 characters of the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d96e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table found!\n",
      "<table class=\"stats_table sortable min_width force_mobilize\" data-cols-to-freeze=\",2\" id=\"results2023-202491_home_away\">\n",
      " <caption>\n",
      "  Premier League Table\n",
      " </caption>\n",
      " <colgroup>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      "  <col/>\n",
      " </colgroup>\n",
      " <thead>\n",
      "  <tr class=\"over_header\">\n",
      "   <th aria-label=\"\" class=\"over_header center\" colspan=\"2\" data-stat=\"\">\n",
      "   </th>\n",
      "   <th aria-label=\"\" class=\"over_header center group_start\" colspan=\"13\" data-stat=\"header_home\">\n",
      "    Home\n",
      "   </th>\n",
      "   <th aria-label=\"\" class=\"over_header center group_start\" colspan=\"13\" data-stat=\"header_away\">\n",
      "    Away\n",
      "   </th>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <th aria-label=\"Rank\" class=\"poptip sort_default_asc center\" data-stat=\"rank\" data-tip=\"&lt;strong&gt;Rank&lt;/strong&gt;&lt;br&gt;Squad finish in competition&lt;br&gt;Finish within the l\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Construct the table ID dynamically based on the test season\n",
    "table_id = \"results2023-202491_home_away\"  # Replace with the correct ID for the test season\n",
    "\n",
    "# Locate the Home/Away Table using its ID\n",
    "table = soup.find('table', {'id': table_id})\n",
    "\n",
    "if table:\n",
    "    print(\"Table found!\")  # Confirm the table was located\n",
    "    print(table.prettify()[:1000])  # Print the first 1000 characters of the table for inspection\n",
    "else:\n",
    "    print(\"Table not found.\")  # Notify if the table could not be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dac2ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['', 'header_home', 'header_away', 'rank', 'team', 'home_games', 'home_wins', 'home_ties', 'home_losses', 'home_goals_for', 'home_goals_against', 'home_goal_diff', 'home_points', 'home_points_avg', 'home_xg_for', 'home_xg_against', 'home_xg_diff', 'home_xg_diff_per90', 'away_games', 'away_wins', 'away_ties', 'away_losses', 'away_goals_for', 'away_goals_against', 'away_goal_diff', 'away_points', 'away_points_avg', 'away_xg_for', 'away_xg_against', 'away_xg_diff', 'away_xg_diff_per90', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank']\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list for headers\n",
    "headers = []\n",
    "\n",
    "# Extract headers from <th> elements\n",
    "for th in table.find_all('th'):\n",
    "    if 'data-stat' in th.attrs:\n",
    "        headers.append(th['data-stat'])  # Append the 'data-stat' attribute to the headers list\n",
    "\n",
    "# Print the extracted headers for verification\n",
    "print(\"Headers:\", headers)  # Print the headers to confirm they match the table columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb1f3293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "['Manchester City', '19', '14', '5', '0', '51', '16', '+35', '47', '2.47', '40.7', '14.0', '+26.7', '+1.41', '19', '14', '2', '3', '45', '18', '+27', '44', '2.32', '39.8', '21.6', '+18.2', '+0.96']\n",
      "['Arsenal', '19', '15', '2', '2', '48', '16', '+32', '47', '2.47', '43.5', '13.5', '+30.0', '+1.58', '19', '13', '3', '3', '43', '13', '+30', '42', '2.21', '32.6', '14.5', '+18.2', '+0.96']\n",
      "['Liverpool', '19', '15', '3', '1', '49', '17', '+32', '48', '2.53', '54.7', '17.6', '+37.1', '+1.95', '19', '9', '7', '3', '37', '24', '+13', '34', '1.79', '33.0', '28.1', '+4.9', '+0.26']\n",
      "['Aston Villa', '19', '12', '4', '3', '48', '28', '+20', '40', '2.11', '39.0', '26.3', '+12.7', '+0.67', '19', '8', '4', '7', '28', '33', '-5', '28', '1.47', '24.3', '33.6', '-9.3', '-0.49']\n",
      "['Tottenham', '19', '13', '0', '6', '38', '27', '+11', '39', '2.05', '39.2', '29.3', '+9.9', '+0.52', '19', '7', '6', '6', '36', '34', '+2', '27', '1.42', '28.9', '34.1', '-5.2', '-0.27']\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list for rows\n",
    "rows = []\n",
    "\n",
    "# Extract rows from <tr> elements\n",
    "for row in table.find_all('tr'):\n",
    "    cells = [cell.text.strip() for cell in row.find_all('td')]  # Extract text from each <td> element\n",
    "    if cells:  # Skip empty rows\n",
    "        rows.append(cells)  # Append non-empty rows to the rows list\n",
    "\n",
    "# Print the first few rows for verification\n",
    "print(\"First few rows:\")  # Print a message before displaying rows\n",
    "for row in rows[:5]:\n",
    "    print(row)  # Print the first 5 rows to confirm the data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "804e5157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['', 'header_home', 'header_away', 'rank', 'team', 'home_games', 'home_wins', 'home_ties', 'home_losses', 'home_goals_for', 'home_goals_against', 'home_goal_diff', 'home_points', 'home_points_avg', 'home_xg_for', 'home_xg_against', 'home_xg_diff', 'home_xg_diff_per90', 'away_games', 'away_wins', 'away_ties', 'away_losses', 'away_goals_for', 'away_goals_against', 'away_goal_diff', 'away_points', 'away_points_avg', 'away_xg_for', 'away_xg_against', 'away_xg_diff', 'away_xg_diff_per90', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank', 'rank']\n",
      "First few rows:\n",
      "['Manchester City', '19', '14', '5', '0', '51', '16', '+35', '47', '2.47', '40.7', '14.0', '+26.7', '+1.41', '19', '14', '2', '3', '45', '18', '+27', '44', '2.32', '39.8', '21.6', '+18.2', '+0.96']\n",
      "['Arsenal', '19', '15', '2', '2', '48', '16', '+32', '47', '2.47', '43.5', '13.5', '+30.0', '+1.58', '19', '13', '3', '3', '43', '13', '+30', '42', '2.21', '32.6', '14.5', '+18.2', '+0.96']\n",
      "['Liverpool', '19', '15', '3', '1', '49', '17', '+32', '48', '2.53', '54.7', '17.6', '+37.1', '+1.95', '19', '9', '7', '3', '37', '24', '+13', '34', '1.79', '33.0', '28.1', '+4.9', '+0.26']\n",
      "['Aston Villa', '19', '12', '4', '3', '48', '28', '+20', '40', '2.11', '39.0', '26.3', '+12.7', '+0.67', '19', '8', '4', '7', '28', '33', '-5', '28', '1.47', '24.3', '33.6', '-9.3', '-0.49']\n",
      "['Tottenham', '19', '13', '0', '6', '38', '27', '+11', '39', '2.05', '39.2', '29.3', '+9.9', '+0.52', '19', '7', '6', '6', '36', '34', '+2', '27', '1.42', '28.9', '34.1', '-5.2', '-0.27']\n",
      "Number of headers: 27\n",
      "Number of columns in rows: 27\n"
     ]
    }
   ],
   "source": [
    "# Print headers and rows for debugging\n",
    "print(\"Headers:\", headers)\n",
    "print(\"First few rows:\")\n",
    "for row in rows[:5]:\n",
    "    print(row)\n",
    "\n",
    "# Keep only the relevant headers (columns 5 to 31)\n",
    "headers = headers[4:31]  # Python uses 0-based indexing, so 4:31 gives columns 5â€“31\n",
    "\n",
    "# Verify the number of headers matches the number of columns in rows\n",
    "print(f\"Number of headers: {len(headers)}\")\n",
    "print(f\"Number of columns in rows: {len(rows[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccb600ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame preview:\n",
      "              team home_games home_wins home_ties home_losses home_goals_for  \\\n",
      "0  Manchester City         19        14         5           0             51   \n",
      "1          Arsenal         19        15         2           2             48   \n",
      "2        Liverpool         19        15         3           1             49   \n",
      "3      Aston Villa         19        12         4           3             48   \n",
      "4        Tottenham         19        13         0           6             38   \n",
      "\n",
      "  home_goals_against home_goal_diff home_points home_points_avg  ...  \\\n",
      "0                 16            +35          47            2.47  ...   \n",
      "1                 16            +32          47            2.47  ...   \n",
      "2                 17            +32          48            2.53  ...   \n",
      "3                 28            +20          40            2.11  ...   \n",
      "4                 27            +11          39            2.05  ...   \n",
      "\n",
      "  away_losses away_goals_for away_goals_against away_goal_diff away_points  \\\n",
      "0           3             45                 18            +27          44   \n",
      "1           3             43                 13            +30          42   \n",
      "2           3             37                 24            +13          34   \n",
      "3           7             28                 33             -5          28   \n",
      "4           6             36                 34             +2          27   \n",
      "\n",
      "  away_points_avg away_xg_for away_xg_against away_xg_diff away_xg_diff_per90  \n",
      "0            2.32        39.8            21.6        +18.2              +0.96  \n",
      "1            2.21        32.6            14.5        +18.2              +0.96  \n",
      "2            1.79        33.0            28.1         +4.9              +0.26  \n",
      "3            1.47        24.3            33.6         -9.3              -0.49  \n",
      "4            1.42        28.9            34.1         -5.2              -0.27  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with the aligned headers and rows\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify alignment\n",
    "print(\"DataFrame preview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67e0d63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:\\Users\\matth\\OneDrive\\Documents\\data_science_project\\premier-league-home-advantage\\data\\raw_data\\2023-2024_home_away_stats.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to save the scraped data\n",
    "save_dir = r\"C:\\Users\\matth\\OneDrive\\Documents\\data_science_project\\premier-league-home-advantage\\data\\raw_data\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = os.path.join(save_dir, \"2023-2024_home_away_stats.csv\")\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Print confirmation message\n",
    "print(f\"Data saved to {file_path}\")  # Confirm the file has been saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa0f0801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for season: 2018-2019\n",
      "Data saved to C:\\Users\\matth\\OneDrive\\Documents\\data_science_project\\premier-league-home-advantage\\data\\raw_data\\2018-2019_home_away_stats.csv\n",
      "Scraping data for season: 2019-2020\n",
      "Data saved to C:\\Users\\matth\\OneDrive\\Documents\\data_science_project\\premier-league-home-advantage\\data\\raw_data\\2019-2020_home_away_stats.csv\n",
      "Scraping data for season: 2020-2021\n",
      "Data saved to C:\\Users\\matth\\OneDrive\\Documents\\data_science_project\\premier-league-home-advantage\\data\\raw_data\\2020-2021_home_away_stats.csv\n",
      "Scraping data for season: 2021-2022\n",
      "Data saved to C:\\Users\\matth\\OneDrive\\Documents\\data_science_project\\premier-league-home-advantage\\data\\raw_data\\2021-2022_home_away_stats.csv\n",
      "Scraping data for season: 2022-2023\n",
      "Data saved to C:\\Users\\matth\\OneDrive\\Documents\\data_science_project\\premier-league-home-advantage\\data\\raw_data\\2022-2023_home_away_stats.csv\n",
      "Scraping data for season: 2023-2024\n",
      "Data saved to C:\\Users\\matth\\OneDrive\\Documents\\data_science_project\\premier-league-home-advantage\\data\\raw_data\\2023-2024_home_away_stats.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Define the list of seasons and base URL\n",
    "seasons = [\"2018-2019\", \"2019-2020\", \"2020-2021\", \"2021-2022\", \"2022-2023\", \"2023-2024\"]\n",
    "base_url = \"https://fbref.com/en/comps/9/{season}/{season}-Premier-League-Stats\"\n",
    "\n",
    "# Define the directory to save the scraped data\n",
    "save_dir = r\"C:\\Users\\matth\\OneDrive\\Documents\\data_science_project\\premier-league-home-advantage\\data\\raw_data\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Function to scrape data for a single season\n",
    "def scrape_season(season):\n",
    "    print(f\"Scraping data for season: {season}\")\n",
    "    \n",
    "    # Construct the URL for the current season\n",
    "    url = base_url.format(season=season)\n",
    "    \n",
    "    # Fetch the HTML content\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data for season {season}. Status code: {response.status_code}\")\n",
    "        return\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Locate the Home/Away Table\n",
    "    table_id = f\"results{season}91_home_away\"\n",
    "    table = soup.find('table', {'id': table_id})\n",
    "    \n",
    "    if not table:\n",
    "        print(f\"Table not found for season {season}. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    # Extract headers\n",
    "    headers = []\n",
    "    for th in table.find_all('th'):\n",
    "        if 'data-stat' in th.attrs:\n",
    "            headers.append(th['data-stat'])\n",
    "    \n",
    "    # Keep only the relevant headers (columns 5 to 31)\n",
    "    headers = headers[4:31]\n",
    "    \n",
    "    # Extract rows\n",
    "    rows = []\n",
    "    for row in table.find_all('tr'):\n",
    "        cells = [cell.text.strip() for cell in row.find_all('td')]\n",
    "        if cells:  # Skip empty rows\n",
    "            rows.append(cells)\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    \n",
    "    # Define the file path for the CSV file\n",
    "    file_path = os.path.join(save_dir, f\"{season}_home_away_stats.csv\")\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    \n",
    "    # Add a delay to avoid overloading the server\n",
    "    time.sleep(3)\n",
    "\n",
    "# Loop through all seasons and scrape their data\n",
    "for season in seasons:\n",
    "    scrape_season(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca722cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
