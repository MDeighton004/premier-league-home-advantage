# Premier League Home Advantage Analysis (2018/19 - 2023/24)

**Author:** Matthew Deighton
**Candidate Number:** 027529
**Date:** April 21, 2025

## Project Description

This project investigates the factors influencing home advantage in the English Premier League using data from the 2018/19 season through to the 2023/24 season. The analysis explores overall trends in home advantage and examines potential micro-level drivers, specifically focusing on the impact of crowd presence (leveraging the COVID-19 pandemic period) and match scheduling (kick-off time and day of the week). The final output is presented as a data-driven blog post.

## Repository Structure

* '/code': Contains the Jupyter Notebooks used for data collection, data cleaning, and analysis, along with corresponding PDF versions.

* '/data': Contains subfolders for raw and processed data.
	* '/data/raw_data/': Contains all the raw data collected from scraping the match-level and team-level data
	* '/data/processed_data/': Contains the cleaned datasets used by the analysis notebook.

* '/output': Contains outputs generated by the analysis code.
	* '/output/figures/': Contains saved plots and visualisations.

* 'README.md': This file, explaining the project.

* 'LICENSE': This project is licensed under the terms specified in the 'LICENSE' file.

* 'blog.txt': Contains links to the final blog post and the GitHub repository.

## Data

The analysis relies on two main datasets derived from statistics scraped from FBref.com (https://fbref.com/en/):
1. **Match Data:** Contains match-level details (date, time, teams, score, xG, attendance, venue, referee) for all PL games from 2018/19 to 2023/24. Stored in 'data/processed_data/all_seasons_match_data.csv'.

2. **Seasonal Team Data:** Contains seasonal home/away stats per team (points, goals, xG difference etc.). Stored in 'data/processed_data/all_seasons_team_data.csv'.
*(Note: Data scraping performed using Python libraries 'requests' and 'BeautifulSoup4'. Cleaning performed using 'pandas')*.

## Setup and Requirements

* **Software:** Python 3.x (Anaconda distribution recommended).
* **Key Python Libraries:**
	* 'pandas'
	* 'numpy'
	* 'matplotlib'
	* 'seaborn'
	* 'statsmodels'
	* 'requests'
	* 'beautifulsoup4'
	* 'os'
	* 'time'
* **Installation:** These libraries can typically be installed via pip or conda (e.g., 'pip install pandas numpy matplotlib seaborn statsmodels requests beautifulsoup time'). Most are included in standard Anaconda distributions.

## How to Run

1. **Clone the Repository:** Clone this GitHub repository to your local machine.
2. **Check Requirements:** Ensure you have Python 3.x and the required libraries listed above installed in your environment.
3. **Data:** Ensure the processed data files required for the analysis ('all_seasons_match_data.csv', 'all_seasons_team_data.csv') are present in the '/data/processed_data/' directory.
4. **Run Analysis Notebooks:**
	* First, open and run the Jupyter Notebook located at 'code/1_analysis.ipynb' from top to bottom. This notebook performs the initial analysis steps and macro trend analysis.
	* Second, open and run the Jupyter Notebook located at 'code/2_analysis.ipynb' from top to bottom. This notebook performs the micro-driver analysis, including regressions and time/day effects.
5. **Outputs:** The notebooks will perform the analysis, display key results, and save output plots to the '/output/figures/' directory.

## Outputs

* Analysis results and interpretations are presented in the Jupyter Notebooks 'code/1_analysis' and 'code/2_analysis.ipynb'.
* Generated plots are saved as '.png' files in the '/output/figures/' directory.
* The final narrative and findings are presented in the data-driven blog post (link in 'blog.txt').